import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Input, Dense, Flatten
from keras.models import Model
from keras.utils import to_categorical
from keras.utils import plot_model
from sklearn.metrics import confusion_matrix

# Load the training and testing data into memory.
drive.mount('/content/drive', True)

# Set up paths
drive_path = '/content/drive/MyDrive/'  # Adjust the path based on your Google Drive folder structure
main_folder = 'Colab Notebooks/BrainTumorsDataset'
train_folder = 'Training'
test_folder = 'Testing'

# Function to load and preprocess image data with minimal augmentation
def load_image_data(folder_path):
    datagen = ImageDataGenerator(rescale=1./255, validation_split=0.1)  # Use a validation split
    data_generator = datagen.flow_from_directory(
        folder_path,
        target_size=(128, 128),
        batch_size=32,
        class_mode='input',
        subset='training',  # Use only training data
        shuffle=True
    )
    return data_generator

# Load training and testing image data
train_data_generator = load_image_data(os.path.join(drive_path, main_folder, train_folder))
test_data_generator = load_image_data(os.path.join(drive_path, main_folder, test_folder))

# Display some of the training images
plt.figure(figsize=(12, 12))
for i in range(20):
    img, label = train_data_generator.next()
    plt.subplot(4, 5, i+1)
    plt.imshow(img[0])
    plt.title(f"Class: {np.argmax(label[0])}")
    plt.axis("off")

plt.show()

# Encoder architecture for the first autoencoder
input_img = Input(shape=(128, 128, 3))  # Adjust the input shape based on your image properties
encoded = Dense(120, activation='sigmoid', name='Encoder')(input_img)
decoded = Dense(128 * 128 * 3, activation='sigmoid', name='Decoder')(encoded)

# Autoencoder model
autoencoder = Model(input_img, decoded)
encoder1 = Model(input_img, encoded)

autoencoder.compile(optimizer='adam', loss='mean_squared_error')

# Train the first autoencoder
autoencoder.fit(train_data_generator, epochs=100, shuffle=True, validation_data=test_data_generator)

# Encoder architecture for the second autoencoder
input_encoded = Input(shape=(120,))
encoded2 = Dense(40, activation='sigmoid', name='Encoder_2')(input_encoded)
decoded2 = Dense(120, activation='sigmoid', name='Decoder_2')(encoded2)

# Second autoencoder model
autoencoder2 = Model(input_encoded, decoded2)
encoder2 = Model(input_encoded, encoded2)

autoencoder2.compile(optimizer='adam', loss='mean_squared_error')

# Train the second autoencoder
autoencoder2.fit(train_data_generator, epochs=100, shuffle=True, validation_data=test_data_generator)

# Softmax layer
input_softmax = Input(shape=(40,))
softmax_layer = Dense(10, activation='softmax', name='Softmax')(input_softmax)

# Softmax model
softnet = Model(input_softmax, softmax_layer)
softnet.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the softmax layer
softnet.fit(encoder2.predict(encoder1.predict(train_data_generator)), 
            to_categorical(train_data_generator.classes), 
            epochs=100, batch_size=256, shuffle=True, validation_split=0.1)

# View the structure of the softmax network
plot_model(softnet, to_file='softmax_model.png', show_shapes=True, show_layer_names=True)

# Stacked model
input_stacked = Input(shape=(128, 128, 3))  # Adjust the input shape based on your image properties
useModel1 = encoder1(input_stacked)
useModel2 = encoder2(useModel1)
useModel3 = softnet(useModel2)

stacked_ae = Model(input_stacked, useModel3)
stacked_ae.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
stacked_ae.summary()

# Train the stacked model
stacked_ae.fit(train_data_generator, epochs=100, shuffle=True, validation_data=test_data_generator)

# Evaluate the model on the test set
evaluation_result = stacked_ae.evaluate_generator(test_data_generator)
print("Test Accuracy:", evaluation_result[1])

# View the results of the fine-tuning on the confusion matrix
y_classified = np.argmax(stacked_ae.predict_generator(test_data_generator), axis=1)
y_true = test_data_generator.classes

# Visualize Confusion Matrix using sklearn's plot_confusion_matrix
import seaborn as sn
cm = confusion_matrix(y_true, y_classified)

plt.figure(figsize=(12, 10))
sn.heatmap(cm, annot=True, fmt='d', cmap='rocket_r')
plt.title("Confusion Matrix")
plt.ylabel('Output Class')
plt.xlabel('Target Class')
plt.show()

drive.flush_and_unmount()
