# -*- coding: utf-8 -*-
"""ProjectV2.5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P9T-borKzJH-5hFA5zIIOJ66kak_oOfN
"""

import numpy as np
import matplotlib.pyplot as plt

# Method 1 import
from google.colab import drive
import os


import tensorflow as tf
from tensorflow.keras import Sequential
from tensorflow.keras import layers
from sklearn.metrics import confusion_matrix, accuracy_score


"""TWO DIFFERENT METHODS OF IMPORTING THE FILES"""
# METHOD 1: Use google drive

# Load the training and testing data into memory.
drive.mount('/content/drive', True)

# Set up paths
drive_path = '/content/drive/MyDrive/'  # Adjust the path based on your Google Drive folder structure
main_folder = 'Colab Notebooks/BrainTumorsDataset'
train_folder = 'Training'
test_folder = 'Testing'


# METHOD 2: use !git clone
# This loads the datasets into Colab at /content/

# !git clone https://github.com/nbnadolski/BrainTumorsDataset.git


# Load training and testing image data
train_data_generator = tf.keras.utils.image_dataset_from_directory(
    directory=os.path.join(drive_path, main_folder, train_folder),
    # directory="/content/BrainTumorsDataset/Training",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True
)

test_data_generator = tf.keras.utils.image_dataset_from_directory(
    directory=os.path.join(drive_path, main_folder, test_folder),
    # directory="/content/BrainTumorsDataset/Testing",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True
)

"""HERE IS THE END OF BOTH METHODS"""

# Display some of the training images

plt.figure(figsize=(12, 12))
for images, labels in train_data_generator.take(1):
  for i in range(20):
    plt.subplot(4, 5, i+1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(train_data_generator.class_names[labels[i]])
    plt.axis("off")

plt.show()

# Create a model

model = Sequential([
  layers.Rescaling(1./255, input_shape=(128, 128, 3)),
  layers.Conv2D(16, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(32, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Conv2D(64, 3, padding='same', activation='relu'),
  layers.MaxPooling2D(),
  layers.Flatten(),
  layers.Dense(128, activation='relu'),
  layers.Dense(4)
])

# Compile the model
model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=["accuracy"])

# Train the model
model.fit(train_data_generator, epochs=100)

model.summary()


# Predict
predicted_classes = np.array([])
true_classes =  np.array([])

for x, y in test_data_generator:
  predicted_classes = np.concatenate([predicted_classes,
                       np.argmax(model.predict(x), axis = -1)])
  true_classes = np.concatenate([true_classes, y.numpy()])

print(confusion_matrix(true_classes, predicted_classes))

print("Accuracy score:", accuracy_score(true_classes, predicted_classes))

drive.flush_and_unmount()
